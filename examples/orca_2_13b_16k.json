{
    "model_path": "../../gguf-models/orca-2-13b-16k-q4_k_m.gguf",
    "n_gpu_layers": 35,
    "f16_kv": true,
    "offload_kqv": true,
    "use_mlock": false,
    "embedding": false,
    "n_threads": 8,
    "n_batch": 1024,
    "n_ctx": 8192,
    "last_n_tokens_size": 1024,
    "verbose": true,
    "seed": 42
}